{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com o modelo gerado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FILE_PATH = '/files'\n",
    "local_model_path = f\"${BASE_FILE_PATH}/traning/unsloth/llama-3-8b-bnb-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "prompt =  \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "Instruction:\n",
    "{}\n",
    "\n",
    "Input:\n",
    "{}\n",
    "\n",
    "Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load local model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = local_model_path, # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(model, tokenizer, prompt, instruction, input):\n",
    "  FastLanguageModel.for_inference(model)\n",
    "  prompt_string = prompt.format(\n",
    "          instruction,\n",
    "          input,\n",
    "          \"\",\n",
    "      )\n",
    "  inputs = tokenizer([prompt_string], return_tensors = \"pt\").to(\"cuda\")\n",
    "  text_streamer = TextStreamer(tokenizer)\n",
    "  _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128, temperature = 0.7, top_p=0.09, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prompt(model, tokenizer, prompt, \"Describe this product!\", \"Girls Ballet Tutu Neon Pink\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
